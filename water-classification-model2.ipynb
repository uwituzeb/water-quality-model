{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "# import necessary libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data():\n",
    "    \"\"\"\n",
    "    Load water quality dataset and preprocess it for neural network training\n",
    "    \"\"\"\n",
    "    # Load the dataset\n",
    "    df = pd.read_csv('water_potability.csv')\n",
    "    \n",
    "    # Handle missing values (if any)\n",
    "    df = df.fillna(df.median())\n",
    "    \n",
    "    # Separate features and target\n",
    "    X = df.drop('Potability', axis=1)\n",
    "    y = df['Potability']\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    return X_scaled, y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_water_quality_model(input_shape, learning_rate=0.01, dropout_rate=0.3, l2_lambda=0.001):\n",
    "    \"\"\"\n",
    "    Create a neural network model for water potability classification\n",
    "    \n",
    "    Args:\n",
    "        input_shape (int): Number of input features\n",
    "        learning_rate (float): Learning rate for SGD optimizer\n",
    "        dropout_rate (float): Dropout rate for regularization\n",
    "        l2_lambda (float): L2 regularization strength\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        # Input layer with L2 regularization\n",
    "        Dense(64, activation='relu', \n",
    "              input_shape=(input_shape,), \n",
    "              kernel_regularizer=l2(l2_lambda)),\n",
    "        \n",
    "        # Dropout layer for preventing overfitting\n",
    "        Dropout(dropout_rate),\n",
    "        \n",
    "        # Hidden layer with L2 regularization\n",
    "        Dense(32, activation='relu', \n",
    "              kernel_regularizer=l2(l2_lambda)),\n",
    "        \n",
    "        # Another dropout layer\n",
    "        Dropout(dropout_rate),\n",
    "        \n",
    "        # Output layer (binary classification)\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    # Compile the model with Stochastic Gradient Descent\n",
    "    optimizer = SGD(learning_rate=learning_rate, momentum=0.9)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy', 'precision', 'recall', tf.keras.metrics.AUC()]\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training and Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(X, y, test_size=0.3, random_state=42):\n",
    "    \"\"\"\n",
    "   Split data, train the model, and evaluate its performance\n",
    "    \"\"\"\n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state, stratify=y\n",
    "    )\n",
    "    \n",
    "    # Further split validation set\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train, y_train, test_size=0.2, random_state=random_state, stratify=y_train\n",
    "    )\n",
    "    \n",
    "    # Early Stopping Callback\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss',  \n",
    "        patience=30,         \n",
    "        restore_best_weights=True  \n",
    "    )\n",
    "    \n",
    "    # Create and train the model\n",
    "    model = create_water_quality_model(\n",
    "        input_shape=X_train.shape[1], \n",
    "        learning_rate=0.01,     \n",
    "        dropout_rate=0.3,       \n",
    "        l2_lambda=0.001         \n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=200,             \n",
    "        batch_size=32,          \n",
    "        callbacks=[early_stopping],\n",
    "        verbose=0               \n",
    "    )\n",
    "    \n",
    "    # Evaluate the model\n",
    "    train_metrics = model.evaluate(X_train, y_train, verbose=0)\n",
    "    val_metrics = model.evaluate(X_val, y_val, verbose=0)\n",
    "    test_metrics = model.evaluate(X_test, y_test, verbose=0)\n",
    "    \n",
    "    # Compute F1 Score\n",
    "    y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
    "    f1_score = tf.keras.metrics.F1Score()(y_test, y_pred)\n",
    "    \n",
    "    # Plotting Training History\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Model Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Return comprehensive results\n",
    "    return {\n",
    "        'model': model,\n",
    "        'train_metrics': {\n",
    "            'loss': train_metrics[0],\n",
    "            'accuracy': train_metrics[1],\n",
    "            'precision': train_metrics[2],\n",
    "            'recall': train_metrics[3],\n",
    "            'auc': train_metrics[4]\n",
    "        },\n",
    "        'validation_metrics': {\n",
    "            'loss': val_metrics[0],\n",
    "            'accuracy': val_metrics[1],\n",
    "            'precision': val_metrics[2],\n",
    "            'recall': val_metrics[3],\n",
    "            'auc': val_metrics[4]\n",
    "        },\n",
    "        'test_metrics': {\n",
    "            'loss': test_metrics[0],\n",
    "            'accuracy': test_metrics[1],\n",
    "            'precision': test_metrics[2],\n",
    "            'recall': test_metrics[3],\n",
    "            'auc': test_metrics[4]\n",
    "        },\n",
    "        'f1_score': f1_score.numpy(),\n",
    "        'history': history\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Load and preprocess data\n",
    "    X, y = load_and_preprocess_data('water_potability.csv')\n",
    "    \n",
    "    # Train and evaluate the model\n",
    "    results = train_and_evaluate_model(X, y)\n",
    "    \n",
    "    # Print Metrics\n",
    "    print(\"\\n--- Model Performance Metrics ---\")\n",
    "    print(\"\\nTraining Metrics:\")\n",
    "    for metric, value in results['train_metrics'].items():\n",
    "        print(f\"{metric.capitalize()}: {value:.4f}\")\n",
    "    \n",
    "    print(\"\\nValidation Metrics:\")\n",
    "    for metric, value in results['validation_metrics'].items():\n",
    "        print(f\"{metric.capitalize()}: {value:.4f}\")\n",
    "    \n",
    "    print(\"\\nTest Metrics:\")\n",
    "    for metric, value in results['test_metrics'].items():\n",
    "        print(f\"{metric.capitalize()}: {value:.4f}\")\n",
    "    \n",
    "    print(f\"\\nF1 Score: {results['f1_score']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "load_and_preprocess_data() takes 0 positional arguments but 1 was given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[12], line 3\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmain\u001b[39m():\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# Load and preprocess data\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m \u001b[43mload_and_preprocess_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwater_potability.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# Train and evaluate the model\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     results \u001b[38;5;241m=\u001b[39m train_and_evaluate_model(X, y)\n",
      "\u001b[1;31mTypeError\u001b[0m: load_and_preprocess_data() takes 0 positional arguments but 1 was given"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Summary Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<br>\n",
    "| Parameter            | Value               |<br>\n",
    "|---------------------|---------------------|<br>\n",
    "| Regularizer         | L2 (lambda=0.001)   |<br>\n",
    "| Optimizer           | Stochastic Gradient Descent |<br>\n",
    "| Early Stopping      | Monitor val_loss, patience=30 |<br>\n",
    "| Dropout Rate        | 0.3                 |<br>\n",
    "| Learning Rate       | 0.01                |<br>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
